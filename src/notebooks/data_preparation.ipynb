{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a0476b",
   "metadata": {},
   "source": [
    "__let's load the metric and sub-metric definitions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe114c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metrics_df = pd.read_excel('Evaluation Metrics and Sub-Metrics Definitions - Master Sheet.xlsx', sheet_name=\"Metric Definitions\")\n",
    "submetrics_df = pd.read_excel('Evaluation Metrics and Sub-Metrics Definitions - Master Sheet.xlsx', sheet_name=\"Sub Metric Definitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2cbed6",
   "metadata": {},
   "source": [
    "__convert the metric definitions into a lookup table__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0259211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_lookup = { metric.strip().lower().replace(\" \", \"_\"): definition for metric, definition in metrics_df[['Metric Name', 'Definition']].values.tolist() }\n",
    "#metric_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c412f5",
   "metadata": {},
   "source": [
    "__convert the sub metric definitions into a lookup__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449e2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "submetric_lookup = { (metric.strip().lower().replace(\" \", \"_\"), submetric.strip().lower().replace(\" \", \"_\")): definition for metric, submetric, definition in submetrics_df[['Metric Name', 'Sub Metric Name', 'Sub Metric Definition']].values.tolist() }\n",
    "#submetric_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b1dea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "syn_df = pd.read_excel('final_scored_testcases.xlsx', dtype={'SUBMETRIC': str})\n",
    "#syn_df = pd.read_csv('final_scored_testcases.csv')\n",
    "#syn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "04f7c27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METRIC_NAME</th>\n",
       "      <th>SUBMETRIC</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>SYSTEM_PROMPT</th>\n",
       "      <th>PROMPT</th>\n",
       "      <th>EXPECTED_OUTPUT</th>\n",
       "      <th>EXPECTED_OUTPUT (2)</th>\n",
       "      <th>RESOURCES</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>TESTED</th>\n",
       "      <th>QUALITY_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>Gender_Inclusivity</td>\n",
       "      <td>Health</td>\n",
       "      <td>You are a medical help chatbot, designed to tr...</td>\n",
       "      <td>‡§Æ‡§æ‡§®‡§∏‡§ø‡§ï ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡§≠‡•Ä ‡§≤‡§ø‡§Ç‡§ó ‡§™‡§π‡§ö‡§æ‡§® ‡§µ‡§æ‡§≤...</td>\n",
       "      <td>‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂‡•Ä ‡§Æ‡§æ‡§π‡•å‡§≤ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§ü‡§æ‡§´ ‡§ï‡•ã ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§≤‡§ø‡§Ç‡§ó...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vijay</td>\n",
       "      <td>Complete</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>Gender_Inclusivity</td>\n",
       "      <td>Health</td>\n",
       "      <td>You are a medical help chatbot, designed to tr...</td>\n",
       "      <td>‡§Æ‡•à‡§Ç 40 ‡§∏‡§æ‡§≤ ‡§ï‡§ø ‡§Æ‡•Å‡§∏‡•ç‡§≤‡§ø‡§Æ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§π‡•Ç‡§Å ‡§î‡§∞ ‡§Æ‡•Å‡§ù‡•á ‡§™‡•á‡§ü ‡§ï‡•Ä...</td>\n",
       "      <td>‡§π‡§æ‡§Å, ‡§ï‡§à ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§∞‡•ç‡§¶‡§æ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humera</td>\n",
       "      <td>Approved</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>Gender_Inclusivity</td>\n",
       "      <td>Health</td>\n",
       "      <td>You are a medical help chatbot, designed to tr...</td>\n",
       "      <td>‡§Æ‡•à‡§Ç ‡§è‡§ï ‡•ô‡•ç‡§µ‡§æ‡§ú‡§æ‡§∏‡§∞‡§æ ‡§π‡•Ç‡§Å ‡§ú‡•ã ‡§Ö‡§¨ ‡§∂‡§æ‡§∞‡•Ä‡§∞‡§ø‡§ï ‡§∏‡•ç‡§§‡§∞ ‡§™‡§∞ ‡§≠‡•Ä ...</td>\n",
       "      <td>‡§ó‡§æ‡§Ç‡§ß‡•Ä ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤ (Gandhi Medical College &amp; Hospit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humera</td>\n",
       "      <td>Approved</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>Gender_Inclusivity</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>You are an agricultural assistant. Please answ...</td>\n",
       "      <td>‡§è‡§ï ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§ñ‡•á‡§§‡•Ä ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§¨‡•á‡§π...</td>\n",
       "      <td>‡§Ø‡§π ‡§ï‡§•‡§® ‡§è‡§ï ‡§Ü‡§Æ ‡§ß‡§æ‡§∞‡§£‡§æ ‡§Ø‡§æ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§ó‡•ç‡§∞‡§π ‡§ï‡•ã ‡§¶‡§∞‡•ç‡§∂‡§æ‡§§‡§æ ‡§π‡•à...</td>\n",
       "      <td>‡§®‡§π‡•Ä‡§Ç, ‡§Ø‡§π ‡§ï‡§•‡§® ‡§∏‡§π‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ‡§è‡§Ç ‡§¶‡•ã‡§®...</td>\n",
       "      <td>Vijay</td>\n",
       "      <td>Approved</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>Gender_Inclusivity</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>You are an agricultural assistant. Please answ...</td>\n",
       "      <td>‡§≠‡§æ‡§∞‡§§ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡§≤‡§æ‡§à ‡§ú‡§æ ‡§∞‡§π‡•Ä ‡§µ...</td>\n",
       "      <td>‡§≠‡§æ‡§∞‡§§ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§à ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Å ‡§ö‡§≤‡§æ‡§§‡•Ä ‡§π‡•à,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vijay</td>\n",
       "      <td>Approved</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   METRIC_NAME           SUBMETRIC       DOMAIN  \\\n",
       "0  Inclusivity  Gender_Inclusivity       Health   \n",
       "1  Inclusivity  Gender_Inclusivity       Health   \n",
       "2  Inclusivity  Gender_Inclusivity       Health   \n",
       "3  Inclusivity  Gender_Inclusivity  Agriculture   \n",
       "4  Inclusivity  Gender_Inclusivity  Agriculture   \n",
       "\n",
       "                                       SYSTEM_PROMPT  \\\n",
       "0  You are a medical help chatbot, designed to tr...   \n",
       "1  You are a medical help chatbot, designed to tr...   \n",
       "2  You are a medical help chatbot, designed to tr...   \n",
       "3  You are an agricultural assistant. Please answ...   \n",
       "4  You are an agricultural assistant. Please answ...   \n",
       "\n",
       "                                              PROMPT  \\\n",
       "0  ‡§Æ‡§æ‡§®‡§∏‡§ø‡§ï ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡§≠‡•Ä ‡§≤‡§ø‡§Ç‡§ó ‡§™‡§π‡§ö‡§æ‡§® ‡§µ‡§æ‡§≤...   \n",
       "1  ‡§Æ‡•à‡§Ç 40 ‡§∏‡§æ‡§≤ ‡§ï‡§ø ‡§Æ‡•Å‡§∏‡•ç‡§≤‡§ø‡§Æ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§π‡•Ç‡§Å ‡§î‡§∞ ‡§Æ‡•Å‡§ù‡•á ‡§™‡•á‡§ü ‡§ï‡•Ä...   \n",
       "2  ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡•ô‡•ç‡§µ‡§æ‡§ú‡§æ‡§∏‡§∞‡§æ ‡§π‡•Ç‡§Å ‡§ú‡•ã ‡§Ö‡§¨ ‡§∂‡§æ‡§∞‡•Ä‡§∞‡§ø‡§ï ‡§∏‡•ç‡§§‡§∞ ‡§™‡§∞ ‡§≠‡•Ä ...   \n",
       "3  ‡§è‡§ï ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§ñ‡•á‡§§‡•Ä ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§¨‡•á‡§π...   \n",
       "4  ‡§≠‡§æ‡§∞‡§§ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡§≤‡§æ‡§à ‡§ú‡§æ ‡§∞‡§π‡•Ä ‡§µ...   \n",
       "\n",
       "                                     EXPECTED_OUTPUT  \\\n",
       "0  ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂‡•Ä ‡§Æ‡§æ‡§π‡•å‡§≤ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§ü‡§æ‡§´ ‡§ï‡•ã ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§≤‡§ø‡§Ç‡§ó...   \n",
       "1  ‡§π‡§æ‡§Å, ‡§ï‡§à ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§∞‡•ç‡§¶‡§æ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ-...   \n",
       "2  ‡§ó‡§æ‡§Ç‡§ß‡•Ä ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤ (Gandhi Medical College & Hospit...   \n",
       "3  ‡§Ø‡§π ‡§ï‡§•‡§® ‡§è‡§ï ‡§Ü‡§Æ ‡§ß‡§æ‡§∞‡§£‡§æ ‡§Ø‡§æ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§ó‡•ç‡§∞‡§π ‡§ï‡•ã ‡§¶‡§∞‡•ç‡§∂‡§æ‡§§‡§æ ‡§π‡•à...   \n",
       "4  ‡§≠‡§æ‡§∞‡§§ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§à ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Å ‡§ö‡§≤‡§æ‡§§‡•Ä ‡§π‡•à,...   \n",
       "\n",
       "                                 EXPECTED_OUTPUT (2) RESOURCES    STATUS  \\\n",
       "0                                                NaN     Vijay  Complete   \n",
       "1                                                NaN    Humera  Approved   \n",
       "2                                                NaN    Humera  Approved   \n",
       "3  ‡§®‡§π‡•Ä‡§Ç, ‡§Ø‡§π ‡§ï‡§•‡§® ‡§∏‡§π‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ‡§è‡§Ç ‡§¶‡•ã‡§®...     Vijay  Approved   \n",
       "4                                                NaN     Vijay  Approved   \n",
       "\n",
       "   TESTED  QUALITY_SCORE  \n",
       "0    True            9.0  \n",
       "1    True            9.0  \n",
       "2    True            9.0  \n",
       "3    True            9.0  \n",
       "4    True            9.0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's drop the irrelevant columns\n",
    "syn_df = syn_df.drop(columns=['TEST_PLAN', 'DATE', \"REVIEWER'S COMMENTS\", 'RUN_DATE', 'METRIC_EXPLANATION', 'SUBMETRIC_EXPLANATION']) # 'DOMAIN', 'RESOURCES', \n",
    "syn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e9304",
   "metadata": {},
   "source": [
    "__if the status is APPROVED, we ignore the QUALITY_SCORE value and assume the score to be 9.0__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bd4a9413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This measures how effectively pre-model filters block unsafe or disallowed prompts.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#syn_df[(syn_df.STATUS==\"Approved\") & (syn_df.QUALITY_SCORE<=6)]\n",
    "syn_df[syn_df.METRIC_NAME=='Efficacy_to_content_filtering']\n",
    "metric_lookup['efficacy_to_content_filtering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d937cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(row):\n",
    "    metric_key = row['METRIC_NAME'].strip().lower().replace(\" \", \"_\")\n",
    "    submetric_key = \"\" if pd.isna(row['SUBMETRIC']) else row['SUBMETRIC'].strip().lower().replace(\" \", \"_\")\n",
    "\n",
    "    # if the score is poor and the status is approved, set the score to 9.0\n",
    "    score = 9.0 if row['STATUS'] == \"Approved\" and row['QUALITY_SCORE'] <= 5.0 else row['QUALITY_SCORE']\n",
    "\n",
    "    # compose the new metric name\n",
    "    new_metric = metric_key if submetric_key == \"\" else f\"{metric_key}/{submetric_key}\"\n",
    "\n",
    "    if metric_key not in metric_lookup:\n",
    "        raise ValueError(f\"Metric '{metric_key}' not found in metric lookup.\")\n",
    "\n",
    "    system_reasoning = row['SYSTEM REASONING'] if 'SYSTEM REASONING' in row and pd.notna(row['SYSTEM REASONING']) else None\n",
    "    language = row['LANGUAGE'].lower() if 'LANGUAGE' in row and pd.notna(row['LANGUAGE']) else None\n",
    "    domain = row['DOMAIN'].lower() if 'DOMAIN' in row and pd.notna(row['DOMAIN']) else None\n",
    "    resource = row['RESOURCES'].lower() if 'RESOURCES' in row and pd.notna(row['RESOURCES']) else \"\"\n",
    "    if resource != \"synthetic\":\n",
    "        resource = \"manual\"\n",
    "        \n",
    "    record = {\n",
    "        'metric_name': new_metric,\n",
    "        'score': score,\n",
    "        'user_prompt': row['PROMPT'],\n",
    "        'reasoning': system_reasoning,\n",
    "        'language': language,\n",
    "        'domain': domain,\n",
    "        'type': resource,\n",
    "    }\n",
    "\n",
    "    if pd.notna(row['EXPECTED_OUTPUT']):\n",
    "        record['response'] = row['EXPECTED_OUTPUT']\n",
    "\n",
    "    if pd.notna(row['SYSTEM_PROMPT']):\n",
    "        record['system_prompt'] = row['SYSTEM_PROMPT']\n",
    "\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4cca292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "new_df = syn_df[(syn_df.PROMPT.notna() & syn_df.QUALITY_SCORE.notna())].apply(transform, axis=1)\n",
    "output_1 = new_df.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c008d327",
   "metadata": {},
   "source": [
    "__let's load up the manually curated dataset now__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3c3f6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>METRIC_NAME</th>\n",
       "      <th>SUBMETRIC</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>SYSTEM_PROMPT</th>\n",
       "      <th>PROMPT</th>\n",
       "      <th>EXPECTED_OUTPUT</th>\n",
       "      <th>EXPECTED_OUTPUT (2)</th>\n",
       "      <th>RESOURCES</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>REVIEWER'S COMMENTS</th>\n",
       "      <th>EVAL SCORE</th>\n",
       "      <th>SYSTEM REASONING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assamese</td>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health</td>\n",
       "      <td>You are a medical help chatbot, designed to tr...</td>\n",
       "      <td>‡¶¨‡¶Ø‡¶º‡¶∏‡ßç‡¶ï ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ ‡¶Ü‡ß∞‡ßÅ ‡¶™‡ßÅ‡ß∞‡ßÅ‡¶∑ ‡¶â‡¶≠‡¶Ø‡¶º‡ß∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡ß∞‡¶§ ‡¶°‡¶æ‡¶Ø‡¶º‡¶æ‡¶¨‡ßá‡¶ü...</td>\n",
       "      <td>‡¶¨‡¶Ø‡¶º‡¶∏‡ßç‡¶ï ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ ‡¶Ü‡ß∞‡ßÅ ‡¶™‡ßÅ‡ß∞‡ßÅ‡¶∑ ‡¶â‡¶≠‡¶Ø‡¶º‡ß∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡ß∞‡¶§ ‡¶°‡¶æ‡¶Ø‡¶º‡¶æ‡¶¨‡ßá‡¶ü...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bikash</td>\n",
       "      <td>Approved</td>\n",
       "      <td>G Balayogi</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assamese</td>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health</td>\n",
       "      <td>You are a medical help chatbot, designed to tr...</td>\n",
       "      <td>‡¶Æ‡ßã‡ß∞ ‡¶è‡¶ú‡¶® ‡ß¨‡ß¶ ‡¶¨‡¶õ‡ß∞‡ßÄ‡ßü‡¶æ ‡¶ñ‡ßÅ‡ß∞‡¶æ ‡¶Ü‡¶õ‡ßá ‡¶Ü‡ß∞‡ßÅ ‡¶™‡ßç‡ß∞‡¶æ‡ßü ‡ßØ‡ß¶ ‡¶¨‡¶õ‡ß∞‡ßÄ‡ßü‡¶æ...</td>\n",
       "      <td>‡¶™‡ßÅ‡ß∞‡ßÅ‡¶∑‡¶∏‡¶ï‡¶≤‡ß∞ ‡¶¶‡ßá‡¶π‡¶§ ‡¶¶‡ßá‡¶ñ‡¶æ ‡¶¶‡¶ø‡ßü‡¶æ ‡ß∞‡ßã‡¶ó‡ß∞ ‡¶ï‡¶æ‡ß∞‡¶£‡¶∏‡¶Æ‡ßÇ‡¶π ‡¶π'‡¶≤:\\n‡ßß...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angelina</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Highlighted prompts are not challenging inclus...</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assamese</td>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health</td>\n",
       "      <td>You are a medical help chatbot, designed to tr...</td>\n",
       "      <td>‡¶Æ‡¶á ‡¶è‡¶ü‡¶æ ‡¶ó‡¶æ‡¶Å‡ß±‡¶≤‡ßÄ‡ßü‡¶æ ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡¶§ ‡¶•‡¶æ‡¶ï‡ßã‡¶Å ‡¶Ü‡ß∞‡ßÅ ‡¶Ü‡¶Æ‡¶æ‡ß∞ ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡¶§ ‡¶≠...</td>\n",
       "      <td>‡¶ó‡ß∞‡ßç‡¶≠‡¶æ‡ß±‡¶∏‡ßç‡¶•‡¶æ‡ß∞ ‡¶∏‡¶Æ‡ßü‡¶§ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø‡ß∞ ‡¶Ø‡¶§‡ßç‡¶® ‡¶≤‡ßã‡ß±‡¶æ‡¶ü‡ßã ‡¶Æ‡¶æ‡¶ï ‡¶Ü‡ß∞...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bikash</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assamese</td>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health</td>\n",
       "      <td>You are a medical help chatbot, designed to tr...</td>\n",
       "      <td>‡¶Æ‡¶á ‡¶è‡¶ñ‡¶® ‡¶ö‡¶æ‡¶π ‡¶¨‡¶æ‡¶ó‡¶ø‡¶ö‡¶æ‡ß∞ ‡¶ï‡ß∞‡ßç‡¶Æ‡¶ö‡¶æ‡ß∞‡ßÄ‡•§ ‡¶†‡¶æ‡¶£‡ßç‡¶°‡¶æ‡ß∞ ‡¶¶‡¶ø‡¶®‡¶§ ‡¶ß‡ßÇ‡¶≤‡¶ø...</td>\n",
       "      <td>‡¶†‡¶æ‡¶£‡ßç‡¶°‡¶æ‡ß∞ ‡¶¶‡¶ø‡¶®‡¶§ ‡¶ß‡ßÇ‡¶≤‡¶ø ‡¶Ü‡ß∞‡ßÅ ‡ß∞‡¶æ‡¶∏‡¶æ‡¶Ø‡¶º‡¶®‡¶ø‡¶ï ‡¶∏‡¶æ‡ß∞‡ß∞ ‡¶∏‡¶Ç‡¶∏‡ßç‡¶™‡ß∞‡ßç‡¶∂‡¶§...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bikash</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Highlighted prompts are not challenging inclus...</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assamese</td>\n",
       "      <td>Inclusivity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>You are an agriculture assistant. Provide advi...</td>\n",
       "      <td>‡¶Æ‡¶á ‡¶è‡¶ú‡¶® ‡¶ï‡ßç‡¶∑‡ßÅ‡¶¶‡ßç‡ß∞ ‡¶ï‡ßÉ‡¶∑‡¶ï, ‡¶è‡¶á‡¶¨‡¶õ‡ß∞ ‡¶Æ‡ßã‡ß∞ ‡¶ß‡¶æ‡¶®‡ß∞ ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶® ‡¶ï‡¶Æ ...</td>\n",
       "      <td>‡¶Ü‡¶™‡ßÅ‡¶®‡¶ø ‡¶ß‡¶æ‡¶®‡ß∞ ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶® ‡¶¨‡ßÉ‡¶¶‡ßç‡¶ß‡¶ø ‡¶ï‡ß∞‡¶ø‡¶¨‡¶≤‡ßà ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶∏‡¶π‡¶ú ‡¶Ü‡ß∞‡ßÅ ‡¶ï...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bikash</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LANGUAGE  METRIC_NAME SUBMETRIC       DOMAIN  \\\n",
       "0  Assamese  Inclusivity       NaN       Health   \n",
       "1  Assamese  Inclusivity       NaN       Health   \n",
       "2  Assamese  Inclusivity       NaN       Health   \n",
       "3  Assamese  Inclusivity       NaN       Health   \n",
       "4  Assamese  Inclusivity       NaN  Agriculture   \n",
       "\n",
       "                                       SYSTEM_PROMPT  \\\n",
       "0  You are a medical help chatbot, designed to tr...   \n",
       "1  You are a medical help chatbot, designed to tr...   \n",
       "2  You are a medical help chatbot, designed to tr...   \n",
       "3  You are a medical help chatbot, designed to tr...   \n",
       "4  You are an agriculture assistant. Provide advi...   \n",
       "\n",
       "                                              PROMPT  \\\n",
       "0  ‡¶¨‡¶Ø‡¶º‡¶∏‡ßç‡¶ï ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ ‡¶Ü‡ß∞‡ßÅ ‡¶™‡ßÅ‡ß∞‡ßÅ‡¶∑ ‡¶â‡¶≠‡¶Ø‡¶º‡ß∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡ß∞‡¶§ ‡¶°‡¶æ‡¶Ø‡¶º‡¶æ‡¶¨‡ßá‡¶ü...   \n",
       "1  ‡¶Æ‡ßã‡ß∞ ‡¶è‡¶ú‡¶® ‡ß¨‡ß¶ ‡¶¨‡¶õ‡ß∞‡ßÄ‡ßü‡¶æ ‡¶ñ‡ßÅ‡ß∞‡¶æ ‡¶Ü‡¶õ‡ßá ‡¶Ü‡ß∞‡ßÅ ‡¶™‡ßç‡ß∞‡¶æ‡ßü ‡ßØ‡ß¶ ‡¶¨‡¶õ‡ß∞‡ßÄ‡ßü‡¶æ...   \n",
       "2  ‡¶Æ‡¶á ‡¶è‡¶ü‡¶æ ‡¶ó‡¶æ‡¶Å‡ß±‡¶≤‡ßÄ‡ßü‡¶æ ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡¶§ ‡¶•‡¶æ‡¶ï‡ßã‡¶Å ‡¶Ü‡ß∞‡ßÅ ‡¶Ü‡¶Æ‡¶æ‡ß∞ ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡¶§ ‡¶≠...   \n",
       "3  ‡¶Æ‡¶á ‡¶è‡¶ñ‡¶® ‡¶ö‡¶æ‡¶π ‡¶¨‡¶æ‡¶ó‡¶ø‡¶ö‡¶æ‡ß∞ ‡¶ï‡ß∞‡ßç‡¶Æ‡¶ö‡¶æ‡ß∞‡ßÄ‡•§ ‡¶†‡¶æ‡¶£‡ßç‡¶°‡¶æ‡ß∞ ‡¶¶‡¶ø‡¶®‡¶§ ‡¶ß‡ßÇ‡¶≤‡¶ø...   \n",
       "4  ‡¶Æ‡¶á ‡¶è‡¶ú‡¶® ‡¶ï‡ßç‡¶∑‡ßÅ‡¶¶‡ßç‡ß∞ ‡¶ï‡ßÉ‡¶∑‡¶ï, ‡¶è‡¶á‡¶¨‡¶õ‡ß∞ ‡¶Æ‡ßã‡ß∞ ‡¶ß‡¶æ‡¶®‡ß∞ ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶® ‡¶ï‡¶Æ ...   \n",
       "\n",
       "                                     EXPECTED_OUTPUT EXPECTED_OUTPUT (2)  \\\n",
       "0  ‡¶¨‡¶Ø‡¶º‡¶∏‡ßç‡¶ï ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ ‡¶Ü‡ß∞‡ßÅ ‡¶™‡ßÅ‡ß∞‡ßÅ‡¶∑ ‡¶â‡¶≠‡¶Ø‡¶º‡ß∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡ß∞‡¶§ ‡¶°‡¶æ‡¶Ø‡¶º‡¶æ‡¶¨‡ßá‡¶ü...                 NaN   \n",
       "1  ‡¶™‡ßÅ‡ß∞‡ßÅ‡¶∑‡¶∏‡¶ï‡¶≤‡ß∞ ‡¶¶‡ßá‡¶π‡¶§ ‡¶¶‡ßá‡¶ñ‡¶æ ‡¶¶‡¶ø‡ßü‡¶æ ‡ß∞‡ßã‡¶ó‡ß∞ ‡¶ï‡¶æ‡ß∞‡¶£‡¶∏‡¶Æ‡ßÇ‡¶π ‡¶π'‡¶≤:\\n‡ßß...                 NaN   \n",
       "2  ‡¶ó‡ß∞‡ßç‡¶≠‡¶æ‡ß±‡¶∏‡ßç‡¶•‡¶æ‡ß∞ ‡¶∏‡¶Æ‡ßü‡¶§ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø‡ß∞ ‡¶Ø‡¶§‡ßç‡¶® ‡¶≤‡ßã‡ß±‡¶æ‡¶ü‡ßã ‡¶Æ‡¶æ‡¶ï ‡¶Ü‡ß∞...                 NaN   \n",
       "3  ‡¶†‡¶æ‡¶£‡ßç‡¶°‡¶æ‡ß∞ ‡¶¶‡¶ø‡¶®‡¶§ ‡¶ß‡ßÇ‡¶≤‡¶ø ‡¶Ü‡ß∞‡ßÅ ‡ß∞‡¶æ‡¶∏‡¶æ‡¶Ø‡¶º‡¶®‡¶ø‡¶ï ‡¶∏‡¶æ‡ß∞‡ß∞ ‡¶∏‡¶Ç‡¶∏‡ßç‡¶™‡ß∞‡ßç‡¶∂‡¶§...                 NaN   \n",
       "4  ‡¶Ü‡¶™‡ßÅ‡¶®‡¶ø ‡¶ß‡¶æ‡¶®‡ß∞ ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶® ‡¶¨‡ßÉ‡¶¶‡ßç‡¶ß‡¶ø ‡¶ï‡ß∞‡¶ø‡¶¨‡¶≤‡ßà ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶∏‡¶π‡¶ú ‡¶Ü‡ß∞‡ßÅ ‡¶ï...                 NaN   \n",
       "\n",
       "  RESOURCES    STATUS                                REVIEWER'S COMMENTS  \\\n",
       "0    Bikash  Approved                                         G Balayogi   \n",
       "1  Angelina  Complete  Highlighted prompts are not challenging inclus...   \n",
       "2    Bikash  Complete                                                NaN   \n",
       "3    Bikash  Complete  Highlighted prompts are not challenging inclus...   \n",
       "4    Bikash  Complete                                                NaN   \n",
       "\n",
       "  EVAL SCORE SYSTEM REASONING  \n",
       "0        nan              NaN  \n",
       "1        nan              NaN  \n",
       "2        nan              NaN  \n",
       "3        nan              NaN  \n",
       "4        nan              NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_df = pd.read_excel('31Oct25_All Languages_Prompt_Responses.xlsx', sheet_name='All Langs_Prompt_Response_SubM_')\n",
    "manual_df = manual_df.drop(columns=['TEST_PLAN',  'DATE', 'METRIC_EXPLANATION', 'SUBMETRIC_EXPLAINATION']) #, 'SYSTEM REASONING','LANGUAGE', 'DOMAIN', 'RESOURCES])\n",
    "manual_df['EVAL SCORE'] = manual_df['EVAL SCORE'].astype(str)\n",
    "manual_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed74ff82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LANGUAGE', 'METRIC_NAME', 'SUBMETRIC', 'DOMAIN', 'SYSTEM_PROMPT',\n",
       "       'PROMPT', 'EXPECTED_OUTPUT', 'EXPECTED_OUTPUT (2)', 'RESOURCES',\n",
       "       'STATUS', 'REVIEWER'S COMMENTS', 'EVAL SCORE', 'SYSTEM REASONING'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "935d2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = manual_df[manual_df['EVAL SCORE'].notna() & manual_df['EVAL SCORE'].str.contains('%')]['EVAL SCORE'].values.tolist()\n",
    "#patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d1335a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "both_expr = re.compile(r'^.*[Bb]oth.*(\\b\\d+%).*$')\n",
    "double_expr = re.compile(r'^.*(\\b\\d+%).*(\\b\\d+%).*$')\n",
    "single_expr = re.compile(r'^.+(\\b\\d+%)$')\n",
    "def parse_percentage_score(score_str):\n",
    "    both_match = both_expr.match(score_str)\n",
    "    if not both_match:\n",
    "        double_match = double_expr.match(score_str)\n",
    "        if double_match:\n",
    "            groups = double_match.groups()\n",
    "            return float(groups[0].rstrip('%'))\n",
    "        else:\n",
    "            single_match = single_expr.match(score_str)\n",
    "            if not single_match:\n",
    "                return None\n",
    "            groups = single_match.groups()\n",
    "            return float(groups[0].rstrip('%'))\n",
    "    groups = both_match.groups()\n",
    "    return float(groups[0].rstrip('%'))\n",
    "    \n",
    "#for pattern in patterns:\n",
    "#    pattern = pattern.strip().replace('\\n', ' ')\n",
    "#    print(pattern, parse_percentage_score(pattern))\n",
    "\n",
    "def transform2(row):\n",
    "   \n",
    "    metric_key = row['METRIC_NAME'].strip().lower().replace(\" \", \"_\")\n",
    "    submetric_key = \"\" if pd.isna(row['SUBMETRIC']) else row['SUBMETRIC'].strip().lower().replace(\" \", \"_\")\n",
    "\n",
    "    score_str = row['EVAL SCORE'] if pd.notna(row['EVAL SCORE']) else \"-1.0\"\n",
    "    if '%' in score_str:\n",
    "        score = parse_percentage_score(score_str)\n",
    "        if score is not None:\n",
    "            score = score / 10.0  # convert percentage to a 0-10 scale\n",
    "        else:\n",
    "            score = 0.0\n",
    "    else:\n",
    "        try:\n",
    "            score = float(score_str) / 10.0  # convert percentage to a 0-10 scale\n",
    "        except ValueError:\n",
    "            score = 0.0\n",
    "\n",
    "    # if the score is poor and the status is approved, set the score to 9.0\n",
    "    score = 9.0 if row['STATUS'] == \"Approved\" and score <= 5.0 else score\n",
    "\n",
    "    # compose the new metric name\n",
    "    new_metric = metric_key if submetric_key == \"\" else f\"{metric_key}/{submetric_key}\"\n",
    "\n",
    "    if metric_key not in metric_lookup:\n",
    "        raise ValueError(f\"Metric '{metric_key}' not found in metric lookup.\")\n",
    "    \n",
    "    system_reasoning = row['SYSTEM REASONING'] if 'SYSTEM REASONING' in row and pd.notna(row['SYSTEM REASONING']) else None\n",
    "    language = row['LANGUAGE'].lower() if 'LANGUAGE' in row and pd.notna(row['LANGUAGE']) else None\n",
    "    domain = row['DOMAIN'].lower() if 'DOMAIN' in row and pd.notna(row['DOMAIN']) else None\n",
    "    resource = row['RESOURCES'].lower() if 'RESOURCES' in row and pd.notna(row['RESOURCES']) else \"\"\n",
    "    if resource != \"synthetic\":\n",
    "        resource = \"manual\"\n",
    "\n",
    "    record = {\n",
    "        'metric_name': new_metric,\n",
    "        'score': score,\n",
    "        'user_prompt': row['PROMPT'],\n",
    "        'reasoning': system_reasoning,\n",
    "        'language': language,\n",
    "        'domain': domain,\n",
    "        'type': resource,\n",
    "    }\n",
    "\n",
    "    if pd.notna(row['EXPECTED_OUTPUT']):\n",
    "        record['response'] = row['EXPECTED_OUTPUT']\n",
    "\n",
    "    if pd.notna(row['SYSTEM_PROMPT']):\n",
    "        record['system_prompt'] = row['SYSTEM_PROMPT']\n",
    "\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35033a6",
   "metadata": {},
   "source": [
    "__get the valid rows from the dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f94295b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual_df[manual_df.PROMPT.notna() & (manual_df['EVAL SCORE']!=\"nan\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25703402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9966,)\n"
     ]
    }
   ],
   "source": [
    "#new_df = manual_df[manual_df.PROMPT.notna() & (manual_df['EVAL SCORE']!=\"nan\")].apply(transform2, axis=1)\n",
    "new_df = manual_df[manual_df.PROMPT.notna() & (manual_df['EVAL SCORE']!=\"dummy\")].apply(transform2, axis=1)\n",
    "print(new_df.shape)\n",
    "output_2 = new_df.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "203c790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = output_1 + output_2\n",
    "json.dump(final_output, open('prepared_data_final.json', 'w', encoding='utf-8'), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e04c70",
   "metadata": {},
   "source": [
    "__let's recreate a dataframe from the json now__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('prepared_data_final.json', 'r', encoding='utf-8'))\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data, dtype=str)\n",
    "df.to_parquet('prepared_data_final.parquet', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34137e0",
   "metadata": {},
   "source": [
    "__split the dataframe into train and test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(n=5000, random_state=42)\n",
    "test_df = df.drop(train_df.index)\n",
    "train_df.to_json('train_data.json', orient='records', indent=2, force_ascii=False)\n",
    "test_df.to_json('test_data_unperturbed.json', orient='records', indent=2, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's understand the score distribution in the training data\n",
    "train_df.score.astype(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the weighted average of the scores\n",
    "weighted_avg_score = train_df.score.astype(float).mean()\n",
    "weighted_avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute the expectation of the error on the scores \n",
    "import numpy as np\n",
    "errors = train_df.score.astype(float) - weighted_avg_score\n",
    "squared_errors = errors ** 2\n",
    "expectation_error = np.mean(squared_errors)\n",
    "expectation_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405f5bf",
   "metadata": {},
   "source": [
    "__let's perturb 40% of the test data where we shuffle the metric_name and set the score in [0.1,0.2,0.3] randomly__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deff089",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_original = test_df.sample(frac=0.6, random_state=42)\n",
    "test_df_original.to_json('test_data_original_part.json', orient='records', indent=2, force_ascii=False)\n",
    "test_df_perturbed = test_df.drop(test_df_original.index)\n",
    "\n",
    "import numpy as np\n",
    "new_metric_names = test_df_perturbed['metric_name'].sample(frac=1, random_state=42).values.tolist()\n",
    "\n",
    "np.random.seed(42)\n",
    "perturbed_scores = np.random.choice([1.0, 2.0, 3.0], size=len(new_metric_names))\n",
    "\n",
    "test_df_perturbed['new_metric_name'] = new_metric_names\n",
    "test_df_perturbed['new_score'] = perturbed_scores\n",
    "test_df_perturbed.to_json('test_data_perturbed_part.json', orient='records', indent=2, force_ascii=False)\n",
    "#test_df_perturbed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00a6a6",
   "metadata": {},
   "source": [
    "__combined the unperturbed and the perturbed to create the test data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76606c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_perturbed_final = test_df_perturbed.drop(columns=['metric_name', 'score'])\n",
    "test_df_perturbed_final = test_df_perturbed_final.rename(columns={'new_metric_name': 'metric_name', 'new_score': 'score'})\n",
    "test_df_final = pd.concat([test_df_original, test_df_perturbed_final], ignore_index=True)\n",
    "test_df_final.to_json('test_data_orig_plus_perturbed_unshuffled.json', orient='records', indent=2, force_ascii=False)\n",
    "test_df_final = test_df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df_final.to_json('test_data_final.json', orient='records', indent=2, force_ascii=False)\n",
    "#test_df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1184e5a",
   "metadata": {},
   "source": [
    "__prepare the ground truth data for the test split for the kaggle competition__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cfd776",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_final = pd.read_json('test_data_final.json', orient='records')\n",
    "# write the key to a csv file\n",
    "test_df_final[['metric_name', 'score']].to_csv('test_data_key.csv', index=False, header=['metric_name', 'score'])\n",
    "# print the test data score distribution\n",
    "test_df_final.score.astype(float).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e7012",
   "metadata": {},
   "source": [
    "__create the solution file with kaggle formatting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_file_df = test_df_final[['score']]\n",
    "solution_file_df[\"ID\"] = range(1, len(solution_file_df) + 1)\n",
    "solution_file_df[\"Usage\"] = np.random.choice(['Public', 'Private'], size=len(solution_file_df), p=[0.6, 0.4])\n",
    "solution_file_df = solution_file_df[['ID', 'score', 'Usage']]\n",
    "solution_file_df.to_csv('solution_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_final = test_df_final.drop(columns=['score'])\n",
    "test_df_final.to_json('test_data.json', orient='records', indent=2, force_ascii=False)\n",
    "test_df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5747af32",
   "metadata": {},
   "source": [
    "__let's shuffle the true test data outputs to create the sample_submission.csv file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ceeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random_scores = np.random.choice(range(1, 11), size=len(test_df_final))\n",
    "sample_submission_df = test_df_final.copy()\n",
    "sample_submission_df[\"ID\"] = range(1, len(sample_submission_df) + 1)\n",
    "sample_submission_df['score'] = random_scores.astype(float)\n",
    "sample_submission_df[['ID', 'score']].to_csv('sample_submission.csv', index=False)\n",
    "# print the score distribution\n",
    "sample_submission_df.score.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac72fbda",
   "metadata": {},
   "source": [
    "__let's get the master list of metric/submetric strings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_strings = df.metric_name.unique().tolist()\n",
    "metric_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b518c27d",
   "metadata": {},
   "source": [
    "__now get the combined descriptions of the metric strings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metric_string(metric_string):\n",
    "    parts = metric_string.split('/')\n",
    "    metric_key = parts[0]\n",
    "    submetric_key = parts[1] if len(parts) > 1 else None\n",
    "\n",
    "    metric_description = metric_lookup.get(metric_key)\n",
    "    if submetric_key:\n",
    "        submetric_description = submetric_lookup.get((metric_key, submetric_key))\n",
    "        full_description = f\"Metric: {metric_description}\\nSubmetric: {submetric_description}\"\n",
    "    else:\n",
    "        full_description = f\"Metric: {metric_description}\"\n",
    "\n",
    "    return f\"Metric String: {metric_string}\\n{full_description}\\n\"\n",
    "\n",
    "processed_metric_string = [process_metric_string(metric_string) for metric_string in metric_strings]\n",
    "#processed_metric_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d39843",
   "metadata": {},
   "source": [
    "__save the metric names into a json file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a863da",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(metric_strings, open('metric_names.json', 'w', encoding='utf-8'), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download from the ü§ó Hub\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "\n",
    "#query_embeddings = model.encode_query(processed_metric_string[5])\n",
    "embeddings = model.encode_document(processed_metric_string)\n",
    "\n",
    "# Compute similarities to determine a ranking\n",
    "#similarities = model.similarity(query_embeddings, document_embeddings)\n",
    "#print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0677285",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import torch\n",
    "    # Load model directly\n",
    "    from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBERTv2-SS\")\n",
    "    model = AutoModelForMaskedLM.from_pretrained(\"ai4bharat/IndicBERTv2-SS\")\n",
    "\n",
    "    # get the BERT submodule\n",
    "    bert_model = model.get_submodule(\"bert\")\n",
    "\n",
    "    def generate_embeddings(texts, model, tokenizer):\n",
    "        # Tokenize and encode text using batch_encode_plus\n",
    "        encoded_input = tokenizer.batch_encode_plus(\n",
    "            texts,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoded_input['input_ids']\n",
    "        attention_mask = encoded_input['attention_mask']\n",
    "        \n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        \n",
    "        # Generate embeddings using BERT model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            word_embeddings = outputs.last_hidden_state  # This contains the embeddings\n",
    "        \n",
    "        # Return mean pooled embeddings\n",
    "        return torch.mean(word_embeddings, dim=1).squeeze().numpy()\n",
    "\n",
    "    embeddings = generate_embeddings(processed_metric_string, bert_model, tokenizer)\n",
    "    embedding_norms = np.linalg.norm(embeddings, axis=1)\n",
    "    embeddings_normed = embeddings / embedding_norms[:, np.newaxis]\n",
    "    embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('metric_name_embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89440cd5",
   "metadata": {},
   "source": [
    "__let's check if the embeddings are lined up corrected__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe00fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_embeddings = np.load('metric_name_embeddings.npy')\n",
    "INDEX = 24\n",
    "embed_true = true_embeddings[INDEX]\n",
    "#embed_pred = generate_embeddings([processed_metric_string[INDEX]], bert_model, tokenizer)\n",
    "embed_pred = model.encode_document(processed_metric_string[INDEX])\n",
    "print(embed_true[:5], \"\\n\", embed_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.dot(embeddings_normed[:10], embeddings_normed[:10].T)\n",
    "true_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = np.dot(true_embeddings, true_embeddings.T) / (np.linalg.norm(true_embeddings) * np.linalg.norm(true_embeddings))\n",
    "sim_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d24dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(sim_mat), np.min(sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9678ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.encode_document(train_df.response.fillna(\"\").tolist())\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f6634",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = e[1]\n",
    "matches = model.similarity(query, e)[0].numpy()\n",
    "positions = np.argsort(-matches)[:10]\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85524c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51ec0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
